# Environment Variables for Todo Phase5 Application

# ====================
# Environment Type
# ====================
# Options: development, production, serverless
# - development: Uses SQLite, no DATABASE_URL needed
# - production: Uses PostgreSQL with connection pooling (Kubernetes)
# - serverless: Uses PostgreSQL with NullPool (Vercel/Railway)
ENVIRONMENT=development

# ====================
# Database Configuration
# ====================
# Leave empty for SQLite (local development)
# For PostgreSQL, use one of these formats:

# Local PostgreSQL:
# DATABASE_URL=postgresql://username:password@localhost:5432/todo_phase5

# Docker/Kubernetes PostgreSQL:
# DATABASE_URL=postgresql://todouser:todopass123@postgres:5432/todo_phase5

# Neon/Vercel Postgres:
# DATABASE_URL=postgresql://user:pass@ep-xxx.us-east-2.aws.neon.tech/neondb?sslmode=require

# Railway/Render:
# DATABASE_URL=postgresql://user:pass@containers-us-west-xxx.railway.app:5432/railway

# Supabase:
# DATABASE_URL=postgresql://postgres:password@db.xxx.supabase.co:5432/postgres

DATABASE_URL=

# ====================
# JWT Authentication
# ====================
# Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"
SECRET_KEY=your-secret-key-here-change-in-production

# JWT Algorithm (HS256 recommended)
ALGORITHM=HS256

# Token expiration in minutes (43200 = 30 days)
ACCESS_TOKEN_EXPIRE_MINUTES=43200

# ====================
# Kafka Configuration
# ====================
# Kafka broker address (comma-separated for multiple brokers)
KAFKA_BOOTSTRAP_SERVERS=localhost:9092

# Kafka consumer group ID
KAFKA_CONSUMER_GROUP=fastapi-backend-consumer

# Kafka topics
KAFKA_TOPIC_TASK_EVENTS=task-events
KAFKA_TOPIC_REMINDERS=reminders
KAFKA_TOPIC_TASK_UPDATES=task-updates

# Kafka Authentication (Production)
# Leave empty for local development (no auth)

# Security Protocol: PLAINTEXT, SASL_PLAINTEXT, SSL, SASL_SSL
KAFKA_SECURITY_PROTOCOL=PLAINTEXT

# SASL Authentication (for managed Kafka services)
# Mechanism: PLAIN, SCRAM-SHA-256, SCRAM-SHA-512
# KAFKA_SASL_MECHANISM=SCRAM-SHA-512
# KAFKA_SASL_USERNAME=your-kafka-username
# KAFKA_SASL_PASSWORD=your-kafka-password

# SSL/TLS Configuration (paths to certificate files)
# KAFKA_SSL_CAFILE=/path/to/ca-cert.pem
# KAFKA_SSL_CERTFILE=/path/to/client-cert.pem
# KAFKA_SSL_KEYFILE=/path/to/client-key.pem

# Example: AWS MSK (SASL/SCRAM)
# KAFKA_BOOTSTRAP_SERVERS=b-1.mycluster.xxx.kafka.us-east-1.amazonaws.com:9096
# KAFKA_SECURITY_PROTOCOL=SASL_SSL
# KAFKA_SASL_MECHANISM=SCRAM-SHA-512
# KAFKA_SASL_USERNAME=admin
# KAFKA_SASL_PASSWORD=your-secret-password

# Example: Confluent Cloud
# KAFKA_BOOTSTRAP_SERVERS=pkc-xxx.us-east-1.aws.confluent.cloud:9092
# KAFKA_SECURITY_PROTOCOL=SASL_SSL
# KAFKA_SASL_MECHANISM=PLAIN
# KAFKA_SASL_USERNAME=your-api-key
# KAFKA_SASL_PASSWORD=your-api-secret

# ====================
# OpenAI Configuration (Optional)
# ====================
# For AI-powered chat features
# OPENAI_API_KEY=sk-...

# ====================
# Redis Configuration (WebSocket Scaling)
# ====================
# Redis URL for multi-instance WebSocket broadcasting
# Leave empty for single-instance mode (in-memory WebSocket manager)

# Local Redis:
# REDIS_URL=redis://localhost:6379

# Docker/Kubernetes Redis:
# REDIS_URL=redis://redis:6379

# Redis Cloud/Upstash:
# REDIS_URL=redis://default:password@redis-hostname:6379

# Redis with password:
# REDIS_URL=redis://:password@localhost:6379

REDIS_URL=

# ====================
# CORS Configuration
# ====================
# Allowed origins for CORS (comma-separated)
# ALLOWED_ORIGINS=http://localhost:3000,https://yourdomain.com
